{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/1.png\">\n",
    "\n",
    "# Supervised Machine Learning Approaches in order to Optimise The Performance of Energy Storage Devices on Smart Grids\n",
    "\n",
    "<img src=\"img/2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Introduction\n",
    "\n",
    "  \n",
    "   As it is obvious, wind speed and solar radiation intensity fluctuate during a day, amounts of electrical energy produced by wind power plants and solar power plants are not stable and they do not have fixed power generation during days months and years. One way to smoothing out the fluctuations in energy generation and demand is using an external electrical energy storage like a couple of battery storage, which are able to charge and discharge in the moments that is needed. In this investigation, different regression approaches will be used to optimize battery operation in an smart grid. To optimize moments of charging and discharging, a list of data have been collected by several sensors that measure wind speed, solar intensity, temperature , energy consumption and other factors that are effective. In this optimizing process several regression methods including Linear Regression, Ridge Regression, Lasso Regression and Elastic Net Regression, XGboost and Artificial Neural Network will be used to predict optimize value for battery energy in each moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Data Manegment\n",
    "### 2-1 Data Preparation \n",
    " The data which will be used in this investigation have been collected from several websites in 48 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Data Exploration\n",
    "\n",
    "#### 2-2-1 Initialization\n",
    "****Note: Disable line below if you have installed \"mlxtend\" before.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from mlxtend) (0.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from mlxtend) (47.3.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from mlxtend) (1.19.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from mlxtend) (3.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from mlxtend) (0.20.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from mlxtend) (0.24.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2018.9)\n",
      "Requirement already satisfied: six in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (1.29.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (47.3.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow) (1.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to c:\\users\\hossei~1\\appdata\\local\\temp\\pip-req-build-dra73s7d\n",
      "Requirement already satisfied (use --upgrade to upgrade): tensorflow-docs===0.0.0d2c4f9c3b9714236c19cc7a549b54f79bf44218c- from git+https://github.com/tensorflow/docs in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: astor in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow-docs===0.0.0d2c4f9c3b9714236c19cc7a549b54f79bf44218c-) (0.8.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow-docs===0.0.0d2c4f9c3b9714236c19cc7a549b54f79bf44218c-) (0.9.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow-docs===0.0.0d2c4f9c3b9714236c19cc7a549b54f79bf44218c-) (3.12.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from tensorflow-docs===0.0.0d2c4f9c3b9714236c19cc7a549b54f79bf44218c-) (5.1)\n",
      "Requirement already satisfied: six in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from absl-py->tensorflow-docs===0.0.0d2c4f9c3b9714236c19cc7a549b54f79bf44218c-) (1.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hosseinslt\\anaconda3\\lib\\site-packages (from protobuf->tensorflow-docs===0.0.0d2c4f9c3b9714236c19cc7a549b54f79bf44218c-) (47.3.1)\n",
      "Building wheels for collected packages: tensorflow-docs\n",
      "  Building wheel for tensorflow-docs (setup.py): started\n",
      "  Building wheel for tensorflow-docs (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\HOSSEI~1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-f01ehtu2\\wheels\\eb\\1b\\35\\fce87697be00d2fc63e0b4b395b0d9c7e391a10e98d9a0d97f\n",
      "Successfully built tensorflow-docs\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please run Final.ipynb from the link below if you had any problem with installing necessary deep learning libraries.\n",
    "\n",
    "# https://github.com/HosseinSLT/ML/blob/master/Smart%20Grid/Final.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import os.path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib. pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from pathlib import Path\n",
    "from scipy.stats import iqr\n",
    "from seaborn import pairplot\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.graphics.correlation import plot_corr\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-2 Data examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Loading data and determining the header\n",
    "data_folder = Path(\"data.csv\")\n",
    "data=pd.read_csv(data_folder , header=2)\n",
    "dfr=pd.DataFrame(data)\n",
    "\n",
    "print(\"Data set dimensions : {}\".format(data.shape))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing needless columns and raws\n",
    "dfr.drop(49,axis=0,inplace=True)\n",
    "dfr.drop('Hours', axis=1 , inplace=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "\n",
    "#Maping each category to a vector that contains 1 and 0 denoting the presence or absence of the feature\n",
    "#In \"time\" column 0 means that it is night , 1 shows that is is day and NAN means it is not clear\n",
    "\n",
    "dfr=pd.get_dummies(dfr, prefix=['Time'] , columns=[\"Day or Night\"])\n",
    "\n",
    "day=dfr[\"Time_Day\"]\n",
    "night=dfr[\"Time_Night\"]\n",
    "\n",
    "time=day*2+night\n",
    "time\n",
    "time=time.replace([0, 1, 2], [np.nan, 0, 1])\n",
    "\n",
    "dfr=dfr.drop('Time_Day', axis=1,)\n",
    "dfr=dfr.drop('Time_Night', axis=1,)\n",
    "\n",
    "dfr['time']=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#considering abbreviated name to each feature inorder to easy use\n",
    "\n",
    "df=dfr.copy()\n",
    "\n",
    "\n",
    "df.columns=[\"wind_s\"]+[\"wind_p\"]+[\"ad\"]+[\"solar_r\"]+[\"solar_p\"]+[\"temp\"]+[\"rh\"]+[\"eng\"]+[\"b_eng\"]+[\"time\"]\n",
    "\n",
    "df.index.name= \"NUM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data type from object to float\n",
    "\n",
    "df=df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chenging order of columns\n",
    "df=df[[\"time\",\"wind_s\",\"wind_p\",\"ad\",\"solar_r\",\"solar_p\",\"temp\",\"rh\",\"eng\",\"b_eng\"]]\n",
    "\n",
    "\n",
    "#Defining parameters that will be used further\n",
    "\n",
    "columns=[\"Time\",\"Wind speed (Km/h)\",\"Wind plant working percantage\",\"Air density (Kg/m3)\",\"Solar radietion intensity (Kwh/m2)\",\n",
    "         \"Solar plant working percantage\" ,\"Temprature (C)\",\"Relative humidity (%)\",\"Energy consumption (MWh)\",\n",
    "         \"Battery Energy (Mwh)\"]\n",
    "\n",
    "\n",
    "columns9=[\"Time\",\"Wind speed (Km/h)\",\"Wind plant working percantage\",\"Air density (Kg/m3)\",\"Solar radietion intensity (Kwh/m2)\",\n",
    "         \"Solar plant working percantage\" ,\"Temprature (C)\",\"Relative humidity (%)\",\"Energy consumption (MWh)\"]\n",
    "\n",
    "Z=[\"red\" ,\"skyblue\" , \"green\" , \"orange\" , \"yellow\" , \"purple\" , \"brown\" , \"pink\" , \"darkblue\" , \"darkred\"] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-3 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizing the central tendency, dispersion and shape of a dataset’s distribution\n",
    "df.loc[:, df.columns != 'time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing data histogram plot\n",
    "\n",
    "b=10\n",
    "e=1e-08\n",
    "\n",
    "labelsize=15\n",
    "figsize=(15,5)\n",
    "titlefontsize=25\n",
    "labelfontsize=22\n",
    "blabelfontsize=15\n",
    "\n",
    " \n",
    "    \n",
    "for i, j, z in zip(df.columns , columns , Z) :\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.rc('xtick',labelsize=labelsize)\n",
    "    plt.rc('ytick',labelsize=labelsize)\n",
    "    plt.title(\"{} histogram\".format(j) , fontsize=titlefontsize) \n",
    "    df[i].plot.hist(bins=b, color=z ,figsize=figsize)\n",
    "    plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "    plt.xlabel(j ,fontsize=labelfontsize)\n",
    "    plt.ylabel(\"Frequency\", fontsize=labelfontsize)\n",
    "    F=(np.nanmax(df[i])-np.nanmin(df[i]))/b+e\n",
    "    plt.xticks(np.arange(np.nanmin(df[i]), np.nanmax(df[i])+F, F))\n",
    "    if i=='time':\n",
    "        plt.xticks([0 , 1],[\"Night\",\"Day\"])\n",
    "    plt.show()\n",
    "    if i!='time':\n",
    "        plt.rc('xtick',labelsize=labelsize)\n",
    "        plt.rc('ytick',labelsize=labelsize)\n",
    "        df.boxplot(column=i ,figsize=figsize)\n",
    "        plt.title(\"{} boxplot\".format(j) , fontsize=titlefontsize) \n",
    "        plt.ylabel(j,fontsize=blabelfontsize)\n",
    "        plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "        plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-1 Cheking out Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v=df.shape[0]\n",
    "\n",
    "df=df.drop_duplicates(keep=\"first\") \n",
    "df.reset_index(drop=True , inplace=True)\n",
    "df.index.name= \"NUM\"\n",
    "\n",
    "w=df.shape[0]\n",
    "\n",
    "z=v-w\n",
    "\n",
    "pz=(z/v)*100\n",
    "\n",
    "c=pd.DataFrame({\"Totall Number of Samples\":v , 'Number of Duplicate Samples':z , \"Percentage of Duplicate Sampeles\":pz}\n",
    "               , index=[\" \"])\n",
    "\n",
    "c.plot.bar(color ={\"blue\":v, \"red\":z , \"green\":pz}, figsize=(15,5))\n",
    "plt.title('Duplicate plot', fontsize=25)   \n",
    "plt.legend()\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-2 Checking out Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## counting the number of missing values\n",
    "\n",
    "#NAN=data_df.isna().sum()\n",
    "NAN=df.isnull().sum()\n",
    "Total=df.count()+NAN\n",
    "Percent=(NAN/Total)*100\n",
    "\n",
    "\n",
    "T_N_df=pd.DataFrame({'Number of NAN Samples':NAN , \"Percentage of NAN Samples (%)\":Percent})\n",
    "\n",
    "\n",
    "T_N_df.index=columns\n",
    "T_N_df.plot.bar(color ={\"yellow\":NAN , \"green\":Percent }, figsize=(15,5))\n",
    "plt.title('Not A Number plot', fontsize=25)\n",
    "plt.legend()\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-3 Processing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dff=df.fillna(df.mean())\n",
    "\n",
    "\n",
    "## Remoweing column or rows with more than half missing values\n",
    "df=df.loc[df.count(1) > df.shape[1]/2, df.count(0) > df.shape[0]/2]\n",
    "\n",
    "\n",
    "## Replacing missing values with the average of the real number before and after them\n",
    "df1=df.fillna(method='ffill')\n",
    "df1=df1.fillna(method='bfill')\n",
    "df2=df.fillna(method='bfill')\n",
    "df2=df2.fillna(method='ffill')\n",
    "df=(df1+df2)/2\n",
    "\n",
    "#In the situation that NAN in the \"day\" column is between day and night \n",
    "#according to this project we prefer to guess that it is night instead of day\n",
    "\n",
    "df[\"time\"]=df[\"time\"].replace([0.5], [0])\n",
    "\n",
    "\n",
    "#display(df1)\n",
    "#display(df2)\n",
    "#display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-4 Checking out Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# finding values that are lower than 5 percentile and greater than 95 percentile as outliers\n",
    "\n",
    "L=np.nanpercentile(df, 5, axis=0)\n",
    "H=np.nanpercentile(df, 95, axis=0)\n",
    "\n",
    "\n",
    "Hcount=df[df > H].count()\n",
    "Lcount=df[df < L].count()\n",
    "\n",
    "out_count=Hcount+Lcount\n",
    "out_percent=(out_count/Total)*100\n",
    "\n",
    "Hcount_df=pd.DataFrame({\"Number of High Outliers\":Hcount , \"Number of Low Outliers\":Lcount ,\n",
    "                        'Total Outlier Pecentage (%)':out_percent})\n",
    "\n",
    "\n",
    "Hcount_df=Hcount_df.round(1)\n",
    "Hcount_df.index=columns\n",
    "\n",
    "Hcount_df.plot.bar(color={\"red\":Hcount , \"blue\":Lcount , \"green\":out_percent}, figsize=(15,5))\n",
    "plt.legend()\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-5 Processing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing high outliers with the amount of 95 percentile and low outliers with the amount of 5 percentile\n",
    "\n",
    "dff=pywt.threshold(df, L, 'greater', L) # bozorgtar az L ha ra negahdra baghi ra ba L jaygozin kon\n",
    "dff=pywt.threshold(df, H, 'less', H)\n",
    "\n",
    "\n",
    "dff=pd.DataFrame(dff)\n",
    "dff.columns=df.columns\n",
    "dff.index.name= \"NUM\"\n",
    "dff=dff.round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating features and the target to two table\n",
    "x_raw=dff.drop('b_eng', axis=1,)\n",
    "y=dff['b_eng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Showing the relationship between the features and the target\n",
    "\n",
    "x_plot=x_raw.copy()\n",
    "x_plot.columns=columns9\n",
    "# display(x_plot)\n",
    "for i, j, z in zip(x_raw.columns , columns9 , Z) :\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.rc('xtick',labelsize=labelsize)\n",
    "    plt.rc('ytick',labelsize=labelsize)\n",
    "    plt.title(\"{} vs. Battery Energy\".format(j) , fontsize=titlefontsize) \n",
    "    plt.scatter(x_raw[i], y ,color=z ,edgecolor='k')\n",
    "    plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "    plt.xlabel(j ,fontsize=labelfontsize)\n",
    "    plt.ylabel(\"Battery Energy (kWh)\", fontsize=labelfontsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pairwise scatter plot\n",
    "pairplot(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap plot\n",
    "plt.figure(figsize=(20,16))\n",
    "plt.rc('xtick',labelsize=labelsize)\n",
    "plt.rc('ytick',labelsize=labelsize)\n",
    "cor = dff.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x_raw)\n",
    "# scaler.mean_\n",
    "# scaler.scale_\n",
    "x=pd.DataFrame(scaler.transform(x_raw))\n",
    "x.columns=x_raw.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-6  Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper Method\n",
    "\n",
    "\n",
    "sfs1 = sfs (estimator=LinearRegression(),  \n",
    "           forward=False ,\n",
    "           k_features=\"parsimonious\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sfs1 = sfs1.fit(x, y, custom_feature_names=columns9)\n",
    "\n",
    "\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "feat_cols_names = list(sfs1.k_feature_names_)\n",
    "\n",
    "\n",
    "print(\"Selcted Features are:\")\n",
    "print(feat_cols_names)\n",
    "print(\"SFS score is= %f\" % sfs1.k_score_)\n",
    "x_sfs=x.iloc[:, feat_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Embedded Methods\n",
    "\n",
    "\n",
    "\n",
    "# Ridge\n",
    "print(\"Ridge regression feature selection\")\n",
    "reg_R = RidgeCV(alphas=(0.01, 0.1 , 1 , 10))\n",
    "reg_R.fit(x, y)\n",
    "alpha_R=reg_R.alpha_\n",
    "coef_R = pd.Series(reg_R.coef_, index = columns9)\n",
    "print(*['Alpha =', alpha_R])\n",
    "print(*['Score =', reg_R.score(x, y)])\n",
    "print(\"Coefficients in Ridge regression are:\")\n",
    "display(coef_R)\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "# Lasso\n",
    "print(\"Lasso regression feature selection\")\n",
    "reg_LA = LassoCV(alphas=(0.01, 0.1 , 1 , 10) , cv=3)\n",
    "reg_LA.fit(x, y)\n",
    "alpha_LA=reg_LA.alpha_\n",
    "coef_LA = pd.Series(reg_LA.coef_, index = columns9)\n",
    "print(*['Alpha =', alpha_LA])\n",
    "print(*['Score =', reg_LA.score(x, y)])\n",
    "print(\"Coefficients in Lasso regression are:\")\n",
    "display(coef_LA)\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "# ElasticNet\n",
    "\n",
    "print(\"ElasticNet regression feature selection\")\n",
    "reg_E =  ElasticNetCV(alphas=(0.01, 0.1 , 1 , 10) , cv=3)\n",
    "reg_E.fit(x, y)\n",
    "alpha_E=reg_E.alpha_\n",
    "coef_E = pd.Series(reg_E.coef_, index = columns9)\n",
    "print(*['Alpha =', alpha_E])\n",
    "print(*['Score =', reg_E.score(x, y)])\n",
    "print(\"Coefficients in ElasticNet regression are:\")\n",
    "display(coef_E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing which features have been selected by which method\n",
    "\n",
    "coef_RC=coef_R.copy()\n",
    "coef_LAC=coef_LA.copy()\n",
    "coef_EC=coef_E.copy()\n",
    "\n",
    "coef=pd.DataFrame({\"Ridge regrassion\": coef_RC , \"Lasso regrassion\": coef_LAC , \"ElasticNet regrassion\": coef_EC})  \n",
    "\n",
    "columns=pd.DataFrame(columns9).copy()\n",
    "\n",
    "\n",
    "xx=x.iloc[0,:].copy()\n",
    "xx= pd.Series(xx, index = columns9)\n",
    "\n",
    "xx=pd.DataFrame({\"SFS (Used in Linear, ANN and XGboost)\":xx})\n",
    "xx.iloc[:,0]=\"⨉\"\n",
    "xx.iloc[feat_cols,:]=\"✔\"\n",
    "\n",
    "\n",
    "coef_C=coef.copy()\n",
    "coef_C[\"SFS (Used in Linear, ANN and XGboost)\"]=xx\n",
    "z=-1\n",
    "for i , j , k in zip(coef[\"Ridge regrassion\"] , coef[\"Lasso regrassion\"] , coef [\"ElasticNet regrassion\"]) :\n",
    "    z=z+1\n",
    "    u=columns.iloc[z , 0]\n",
    "    if i==0 :\n",
    "        coef_C.loc[u , \"Ridge regrassion\"]=\"⨉\"\n",
    "    else:\n",
    "        coef_C.loc[u , \"Ridge regrassion\"]=\"✔\"\n",
    "    if j==0 :\n",
    "        coef_C.loc[u , \"Lasso regrassion\"]=\"⨉\"\n",
    "    else:\n",
    "        coef_C.loc[u , \"Lasso regrassion\"]=\"✔\"\n",
    "    if k==0 :\n",
    "        coef_C.loc[u , \"ElasticNet regrassion\"]=\"⨉\"\n",
    "    else:\n",
    "        coef_C.loc[u , \"ElasticNet regrassion\"]=\"✔\"\n",
    "\n",
    "display(coef_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting features coefficients\n",
    "\n",
    "coef.plot.bar(color={ \"blue\":\"Ridge regression\" ,\n",
    "                              \"orange\":\"Lasso regression\" , \"purple\":\"ElasticNet regression\" },\n",
    "                       figsize=figsize)\n",
    "plt.title('Features coefficients', fontsize=titlefontsize)   \n",
    "plt.ylabel('coefficient', fontsize=labelfontsize)\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "x_train_sfs, x_test_sfs, y_train_sfs , y_test_sfs = model_selection.train_test_split(x_sfs, y, test_size=test_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kfold = model_selection.KFold(n_splits=3 , random_state=seed, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2  Regression Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2-1 Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.fit(x_train_sfs, y_train_sfs)\n",
    "result_LT = L.score(x_test_sfs, y_test_sfs)\n",
    "y_pred_LT=L.predict(x_test_sfs)\n",
    "\n",
    "print(\"Accuracy: %.3f%%\" % (result_LT*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.fit(x_sfs, y)\n",
    "results_LK = model_selection.cross_val_score(L, x_sfs, y, cv=kfold)\n",
    "y_pred_LK=L.predict(x_sfs)\n",
    "errors_LK=y_pred_LK-y\n",
    "\n",
    "\n",
    "# model.fit(x, y)\n",
    "# results_LK = model_selection.cross_val_score(L, x, y, cv=kfold)\n",
    "# y_pred_LK=L.predict(x)\n",
    "\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results_LK.mean()*100.0, results_LK.std()*100.0))\n",
    "print (results_LK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2-2 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Ridge(alpha=alpha_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.fit(x_train, y_train)\n",
    "result_RT = R.score(x_test, y_test)\n",
    "y_pred_RT=R.predict(x_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result_RT*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.fit(x, y)\n",
    "results_RK = model_selection.cross_val_score(R, x, y, cv=kfold)\n",
    "y_pred_RK=R.predict(x)\n",
    "errors_RK=y_pred_RK-y\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results_RK.mean()*100.0, results_RK.std()*100.0))\n",
    "print (results_RK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2-3 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA = Lasso (alpha=alpha_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA.fit(x_train, y_train)\n",
    "result_LAT = LA.score(x_test, y_test)\n",
    "y_pred_LAT=LA.predict(x_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result_LAT*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA.fit(x, y)\n",
    "results_LAK = model_selection.cross_val_score(LA, x, y, cv=kfold)\n",
    "y_pred_LAK=LA.predict(x)\n",
    "errors_LAK=y_pred_LAK-y\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results_LAK.mean()*100.0, results_LAK.std()*100.0))\n",
    "print (results_LAK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2-4 ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = ElasticNet(alpha =alpha_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.fit(x_train, y_train)\n",
    "result_ET = E.score(x_test, y_test)\n",
    "y_pred_ET=E.predict(x_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result_ET*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.fit(x, y)\n",
    "results_EK = model_selection.cross_val_score(E, x, y, cv=kfold)\n",
    "y_pred_EK=E.predict(x)\n",
    "errors_EK=y_pred_EK-y\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results_EK.mean()*100.0, results_EK.std()*100.0))\n",
    "print (results_EK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2-5 Artificial Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  ANN = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[len(x_sfs.keys())]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  ANN.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return ANN\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "ANN = KerasRegressor(build_fn=build_model, epochs=EPOCHS, batch_size=5, verbose=0)\n",
    "\n",
    "results = cross_val_score(ANN, x_sfs, y, cv=kfold)\n",
    "print(\"Baseline: %.4f (%.4f) MSE\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "ANN.fit(\n",
    "  x_sfs, y,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[tfdocs.modeling.EpochDots()])\n",
    "\n",
    "y_pred_ANNK = ANN.predict(x_sfs).flatten()\n",
    "errors_ANNK=y_pred_ANNK-y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2-5 XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 1, learning_rate = 0.2,\n",
    "                max_depth = 2 , n_estimators = 100)\n",
    "xg_reg.fit(x_sfs, y)\n",
    "results_XK = model_selection.cross_val_score(xg_reg, x_sfs, y, cv=kfold)\n",
    "y_pred_XK=xg_reg.predict(x_sfs)\n",
    "errors_XK=y_pred_XK-y\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results_XK.mean()*100.0, results_XK.std()*100.0))\n",
    "print (results_XK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted=pd.DataFrame({\"Linear Regression predicted values\": y_pred_LK ,\"Ridge Regression predicted values\" : y_pred_RK,\n",
    "                       \"Lasso Regression predicted values\": y_pred_LAK ,\"ElasticNet Regression predicted values\" : y_pred_EK,\n",
    "                     \"Artificial Neural Network predicted values\": y_pred_ANNK , \"XGBRegressor predicted values\": y_pred_XK})\n",
    "\n",
    "errors=pd.DataFrame({\"Linear Regression errors\": errors_LK ,\"Ridge Regression errors\" : errors_RK,\n",
    "                       \"Lasso Regression errors\": errors_LAK ,\"ElasticNet Regression errors\" : errors_EK,\n",
    "                    \"Artificial Neural Network errors\": errors_ANNK, \"XGBRegressor errors\": errors_XK})\n",
    "\n",
    "AC=pd.DataFrame({\"Accuracy (%) \":(results_LK.mean()*100.0 , results_RK.mean()*100.0 ,results_LAK.mean()*100.0 , results_EK.mean()*100.0 ,results_XK.mean()*100.0)}\n",
    "               , index=(\"Linear Regression\", \"Ridge Regression\" , \"Lasso Regression\" ,\"ElasticNet Regression\" , \"XGBRegressor\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Results and Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting regression methods errors and predicted values\n",
    "colors=[\"red\"]+[\"blue\"]+[\"orange\"]+[\"purple\"]+[\"gray\"]+[\"pink\"]\n",
    "\n",
    "for i, j ,z in zip(predicted.columns, errors.columns , colors) :\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(\" {} vs predicted values\".format(j) , fontsize=22) \n",
    "    plt.scatter(x=predicted[i] , y=errors[j] ,color=z ,edgecolor='k')\n",
    "    plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "    plt.xlabel(\"predicted values\" ,fontsize=labelfontsize)\n",
    "    plt.ylabel(j, fontsize=blabelfontsize)\n",
    "    xmin=min(predicted[i])\n",
    "    xmax =max(predicted[i])\n",
    "    plt.hlines(y=0,xmin=xmin*1.1,xmax=xmax*1.1,color='red',linestyle='--',lw=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#plotting features and diffrent regression models errors\n",
    "\n",
    "for f in errors.columns:\n",
    "    err=errors[f]\n",
    "    for i, j, z in zip(x_raw.columns , columns9 , Z) :\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.title(\"{}\".format(f) , fontsize=22)\n",
    "        plt.scatter(x=x_raw[i],y=err,color=z ,edgecolor='k')\n",
    "        plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "        plt.xlabel(j ,fontsize=labelfontsize)\n",
    "        plt.ylabel(\"errors\", fontsize=labelfontsize)\n",
    "        xmin=min(x_raw[i])\n",
    "        xmax = max(x_raw[i])\n",
    "        plt.hlines(y=0, xmin=xmin*0.9 , xmax=xmax*1.1 , color='red',linestyle='--', lw=3)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting diffrent regression accuracy plot\n",
    "AC.T.plot.bar(color={\"red\":\"Linear regression\" , \"blue\":\"Ridge regression\" ,\n",
    "                    \"orange\":\"Lasso regression\" ,\"purple\":\"ElasticNet regression\" ,\"pink\":\"XGBRegressor\" }\n",
    "             , figsize=(15,5))\n",
    "plt.title('Regression accuracy', fontsize=30)\n",
    "plt.legend()\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Correlation plot\n",
    "\n",
    "pearsonr_LK=sp.stats.pearsonr(y, y_pred_LK)[0]\n",
    "spearmanr_LK=sp.stats.spearmanr(y, y_pred_LK)[0]\n",
    "kendalltau_LK=sp.stats.kendalltau(y, y_pred_LK)[0]\n",
    "\n",
    "pearsonr_RK=sp.stats.pearsonr(y, y_pred_RK)[0]\n",
    "spearmanr_RK=sp.stats.spearmanr(y, y_pred_RK)[0]\n",
    "kendalltau_RK=sp.stats.kendalltau(y, y_pred_RK)[0]\n",
    "\n",
    "pearsonr_LAK=sp.stats.pearsonr(y, y_pred_LAK)[0]\n",
    "spearmanr_LAK=sp.stats.spearmanr(y, y_pred_LAK)[0]\n",
    "kendalltau_LAK=sp.stats.kendalltau(y, y_pred_LAK)[0]\n",
    "\n",
    "pearsonr_EK=sp.stats.pearsonr(y, y_pred_EK)[0]\n",
    "spearmanr_EK=sp.stats.spearmanr(y, y_pred_EK)[0]\n",
    "kendalltau_EK=sp.stats.kendalltau(y, y_pred_EK)[0]\n",
    "\n",
    "pearsonr_ANNK=sp.stats.pearsonr(y, y_pred_ANNK)[0]\n",
    "spearmanr_ANNK=sp.stats.spearmanr(y, y_pred_ANNK)[0]\n",
    "kendalltau_ANNK=sp.stats.kendalltau(y, y_pred_ANNK)[0]\n",
    "\n",
    "pearsonr_XK=sp.stats.pearsonr(y, y_pred_XK)[0]\n",
    "spearmanr_XK=sp.stats.spearmanr(y, y_pred_XK)[0]\n",
    "kendalltau_XK=sp.stats.kendalltau(y, y_pred_XK)[0]\n",
    "\n",
    "\n",
    "\n",
    "r=pd.DataFrame({\"Pearson's r\":(pearsonr_LK,pearsonr_RK,pearsonr_LAK,pearsonr_EK,pearsonr_ANNK,pearsonr_XK), \n",
    "                \"Spearman's rho\":(spearmanr_LK , spearmanr_RK,spearmanr_LAK,spearmanr_EK,spearmanr_ANNK,spearmanr_XK) ,\n",
    "                \" Kendall's tau\":( kendalltau_LK , kendalltau_RK ,kendalltau_LAK,kendalltau_EK,kendalltau_ANNK,kendalltau_XK)}\n",
    "               , index=(\"Linear Regression\", \"Ridge Regression\" , \"Lasso Regression\" ,\"ElasticNet Regression\",\n",
    "                       \"Artificial Neural Network\" ,\"XGBRegressor\"))\n",
    "\n",
    "r.T.plot.bar(color={\"red\":\"Linear regression\" , \"blue\":\"Ridge regression\" ,\n",
    "                    \"orange\":\"Lasso regression\" ,\"purple\":\"ElasticNet regression\",\n",
    "                    \"gray\":\"Artificial Neural Network\" ,\"pink\":\"XGBRegressor\" }\n",
    "             , figsize=(15,5))\n",
    "plt.title('Correlation', fontsize=30)\n",
    "plt.legend(loc=4, prop={'size': 10})\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plotting historgram of regression methods errors\n",
    "\n",
    "b=5\n",
    "errors_r=errors.round(2)\n",
    "\n",
    "for i , z in zip(errors_r.columns , colors):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.rc('xtick',labelsize=labelsize)\n",
    "    plt.rc('ytick',labelsize=labelsize)\n",
    "    plt.hist(errors_r[i],bins=b, color=z ,edgecolor='k')\n",
    "    plt.ylabel('Count', fontsize=labelfontsize)\n",
    "    plt.xlabel(' Errors (Mwh)' , fontsize=labelfontsize)\n",
    "    plt.title(\"Histogram of {}\".format(i) ,fontsize=titlefontsize)\n",
    "    F=(np.nanmax(errors_r[i])-np.nanmin(errors_r[i]))/b+e\n",
    "    plt.xticks(np.arange(np.nanmin(errors_r[i]), np.nanmax(errors_r[i])+F, F))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting Error amounts\n",
    "\n",
    "MSE_LK=mean_squared_error(y, y_pred_LK)\n",
    "r2_LK=r2_score(y, y_pred_LK)\n",
    "RMSE_LK= sqrt (MSE_LK)\n",
    "MAE_LK= mean_absolute_error(y, y_pred_LK)\n",
    "MAPE_LK=np.mean(np.abs((y - y_pred_LK) / y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MSE_RK=mean_squared_error(y, y_pred_RK)\n",
    "r2_RK=r2_score(y, y_pred_RK)\n",
    "RMSE_RK= sqrt (MSE_RK)\n",
    "MAE_RK= mean_absolute_error(y, y_pred_RK)\n",
    "MAPE_RK=np.mean(np.abs((y - y_pred_RK) / y))\n",
    "\n",
    "\n",
    "\n",
    "MSE_LAK=mean_squared_error(y, y_pred_LAK)\n",
    "r2_LAK=r2_score(y, y_pred_LAK)\n",
    "RMSE_LAK= sqrt (MSE_LAK)\n",
    "MAE_LAK= mean_absolute_error(y, y_pred_LAK)\n",
    "MAPE_LAK=np.mean(np.abs((y - y_pred_LAK) / y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MSE_EK=mean_squared_error(y, y_pred_EK)\n",
    "r2_EK=r2_score(y, y_pred_EK)\n",
    "RMSE_EK= sqrt (MSE_EK)\n",
    "MAE_EK= mean_absolute_error(y, y_pred_EK)\n",
    "MAPE_EK=np.mean(np.abs((y - y_pred_EK) / y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MSE_ANNK=mean_squared_error(y, y_pred_ANNK)\n",
    "r2_ANNK=r2_score(y, y_pred_ANNK)\n",
    "RMSE_ANNK= sqrt (MSE_ANNK)\n",
    "MAE_ANNK= mean_absolute_error(y, y_pred_ANNK)\n",
    "MAPE_ANNK=np.mean(np.abs((y - y_pred_ANNK) / y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MSE_XK=mean_squared_error(y, y_pred_XK)\n",
    "r2_XK=r2_score(y, y_pred_XK)\n",
    "RMSE_XK= sqrt (MSE_XK)\n",
    "MAE_XK= mean_absolute_error(y, y_pred_XK)\n",
    "MAPE_XK=np.mean(np.abs((y - y_pred_XK) / y))\n",
    "\n",
    "\n",
    "\n",
    "ERR= pd.DataFrame({'MAE': [MAE_LK , MAE_RK , MAE_LAK , MAE_EK ,MAE_ANNK, MAE_XK],\n",
    "                   'R2': [r2_LK , r2_RK , r2_LAK , r2_EK , r2_ANNK, r2_XK],\n",
    "                   'MSE*1e2': [MSE_LK*100 ,MSE_RK*100 , MSE_LAK*100 , MSE_EK*100 ,MSE_ANNK*100, MSE_XK*100 ] , \n",
    "                   'RMSE':[RMSE_LK , RMSE_RK, RMSE_LAK , RMSE_EK, RMSE_ANNK, RMSE_XK],\n",
    "                   'MAPE':[MAPE_LK , MAPE_RK, MAPE_LAK , MAPE_EK ,MAPE_ANNK, MAPE_XK] ,\n",
    "                   'errors_IQR':[iqr(errors_LK) , iqr(errors_RK) , iqr(errors_LAK) , iqr(errors_EK),\n",
    "                                 iqr(errors_ANNK),iqr(errors_XK)] } ,\n",
    "                    index=[\"Linear Regression\" , \"Ridge Regression\" , \"Lasso Regression\" , \n",
    "                           \"ElasticNet Regression\" ,\"Artificial Neural Network\" ,\"XGBRegressor\"])\n",
    "\n",
    "\n",
    "ERR.T.plot.bar(color={\"red\":\"Linear regression\" , \"blue\":\"Ridge regression\"\n",
    "                      , \"orange\":\"Lasso regression\" , \"purple\":\"ElasticNet regression\",\n",
    "                     \"gray\":\"Artificial Neural Network\" ,\"pink\":\"XGBRegressor\"}, figsize=(15,5))\n",
    "plt.title('Error Amounts', fontsize=30)\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EA25=pd.DataFrame({\"Linear Regression\":y_pred_LK-y , \"Ridge Regression\":y_pred_RK-y \n",
    "                   , \"Lasso Regression\":y_pred_LAK-y , \"ElasticNet Regression\":y_pred_EK-y,\n",
    "                   \"Artificial Neural Network\":y_pred_ANNK-y,\"XGBRegressor\":y_pred_XK-y})\n",
    "\n",
    "EA25.head(25).plot.bar(color={\"red\":\"Linear regression\" , \"blue\":\"Ridge regression\" ,\n",
    "                              \"orange\":\"Lasso regression\" , \"purple\":\"ElasticNet regression\",\n",
    "                              \"gray\":\"Artificial Neural Network\" ,\"pink\":\"XGBRegressor\" }, figsize=figsize)\n",
    "\n",
    "plt.title('Error Amounts in the first 25 samples', fontsize=titlefontsize)   \n",
    "plt.xlabel('Number of Sample', fontsize=labelfontsize)\n",
    "plt.ylabel('Battery Energy (Mwh)', fontsize=labelfontsize)\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "errors.columns=[\"Linear\"]+[\"Ridge\"]+[\"Lasso\"]+[\"ElasticNet\"]+[\"ANN\"]+[\"XGBRegressor\"]\n",
    "\n",
    "errors.boxplot(figsize=figsize)\n",
    "plt.title('Error Box Plot', fontsize=titlefontsize) \n",
    "plt.ylabel('Errors',fontsize=labelfontsize)\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting predicted values for battery energy in all regression models\n",
    "\n",
    "pb=pd.DataFrame({'Real amount':y , \"Linear Regression\":y_pred_LK \n",
    "                 , \"Ridge Regression\":y_pred_RK , \"Lasso Regression\":y_pred_LAK ,\n",
    "                 \"ElasticNet Regression\":y_pred_EK ,\"Artificial Neural Network\":y_pred_ANNK,\n",
    "                 \"XGBRegressor\":y_pred_XK})\n",
    "\n",
    "pb.head(25).plot.bar(color={ \"green\":\"Real amount\" , \"red\":\"Linear regression\" , \"blue\":\"Ridge regression\" ,\n",
    "                            \"orange\":\"Lasso regression\" , \"purple\":\"ElasticNet regression\" , \n",
    "                           \"gray\":\"Artificial Neural Network\" ,\"pink\":\"XGBRegressor\"}, figsize=(17,10))\n",
    "plt.title('Battery storage enregy in the first 25 samples', fontsize=titlefontsize)       \n",
    "plt.xlabel('Number of Sample', fontsize=labelfontsize)\n",
    "plt.ylabel('Battery Energy (Mwh)', fontsize=labelfontsize)\n",
    "EE=np.round(np.mean(abs(y-y_pred_RK)) , 2)\n",
    "plt.yticks(np.arange(np.round(min(y)-EE , 1), max(y)+EE, EE))  \n",
    "plt.legend(loc=1, prop={'size': 10})\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Testing with New Sample\n",
    "Now we can test the controlling system with new data to evaluate that.\n",
    "In order to insert new data please enter the amounts of nine factors which are shown below:\n",
    "\n",
    "***Time, Wind speed (Km/h), Wind plant working percantage, Air density (Kg/m3), Solar radietion intensity (Kwh/m2), Solar plant working percantage, Temprature, Relative humidity (%), Energy consumption (Mwh)***\n",
    "\n",
    "*Remember to insert the amounts with a single space and without comma*\n",
    "\n",
    "*In Time 0 means night and 1 means day*\n",
    "\n",
    "*If you don't know one of requested amounts please enter 'NAN' instead of that*\n",
    "\n",
    "##### Examples:\n",
    "\n",
    " ----> 0 55.0 80 1.23 0 100 25 85 1.3\n",
    "\n",
    " ----> 1 45 60 NAN 1000 75 33 90 1.5\n",
    "\n",
    " ----> 0 53.78 98.05 1.23 352.44 98.54 28.32 85 1.48\n",
    "\n",
    " ----> 1 NAN 40 NAN 700 95 22 75 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1  The input preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NAN=np.nan\n",
    "df2=df.drop(['b_eng'], axis=1)\n",
    "\n",
    "print('Please enter the amounts:')\n",
    "sample=list(input().split())\n",
    "sample= np.array(sample, dtype='float')\n",
    "sample=sample.reshape(1,-1)\n",
    "\n",
    "\n",
    "sample=pd.DataFrame(sample)\n",
    "sample.columns=df2.columns\n",
    "sample=sample.fillna(df.mean())\n",
    "\n",
    "LL=np.nanpercentile(df2, 5, axis=0)\n",
    "HH=np.nanpercentile(df2, 95, axis=0)\n",
    "\n",
    "sample=pywt.threshold(sample, LL, 'greater', LL)\n",
    "sample=pywt.threshold(sample, HH, 'less', HH)\n",
    "\n",
    "sample=pd.DataFrame(sample, index=['Preprossed Input'])\n",
    "\n",
    "sample.columns=columns9\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print('Preprocessed Input is:')\n",
    "sample['Time'] = sample.Time.astype(int)\n",
    "\n",
    "sample=sample.round(2)\n",
    "\n",
    "display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2  Finding an appropriate method according to the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Grid Search to find the best parameters for the KNN classifier to \n",
    "# predict the appropriate regression method  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample=scaler.transform(sample)\n",
    "sample_sfs=sample[: ,feat_cols ]\n",
    "res_abs=pd.DataFrame(errors.abs())\n",
    "best_method=res_abs.idxmin(axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear', degree=1, C=3 )\n",
    "\n",
    "classifier.fit(x,best_method)\n",
    "\n",
    "considered_best_method = classifier.predict(sample)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'] ,\n",
    "               'degree': [1 ,2 , 3, 4, 5, 6 , 7, 8, 9, 10 ],\n",
    "               'C': [1 , 2, 3, 4, 5 , 6, 7, 8,9 , 10 ],\n",
    "               }] \n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(x, best_method)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Classification Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters to optimise the classifier:\", best_parameters)\n",
    "print('---------------------------')\n",
    "\n",
    "\n",
    "\n",
    "if considered_best_method[0]=='Linear':\n",
    "    sample=sample[: ,feat_cols ]\n",
    "    model=L\n",
    "    method='Linear Regression'\n",
    "    print(\"Appropriate method according to the input is Linear Regression\")\n",
    "    print('R-squared percentage for this method is = %.3f%%'  %  (r2_LK*100))\n",
    "if considered_best_method[0]=='Ridge' :\n",
    "    model=R\n",
    "    method='Ridge Regression'\n",
    "    print(\"Appropriate method according to the input is Ridge Regression\")\n",
    "    print('R-squared percentage for this method is = %.3f%%'  %  (r2_RK*100))\n",
    "if considered_best_method[0]=='Lasso':\n",
    "    model=LA\n",
    "    method='Lasso Regression'\n",
    "    print(\"Appropriate method according to the input is Lasso Regression\")\n",
    "    print('R-squared percentage for this method is = %.3f%%'  %  (r2_LAK*100))\n",
    "if considered_best_method[0]=='ElasticNet' :\n",
    "    model=E\n",
    "    method='ElasticNet Regression'\n",
    "    print(\"Appropriate method according to the input is ElasticNet Regression\")\n",
    "    print('R-squared percentage for this method is = %.3f%%'  %  (r2_EK*100))\n",
    "if considered_best_method[0]=='ANN':\n",
    "    sample=sample[: ,feat_cols ]\n",
    "    model=ANN\n",
    "    method='Artificial Neural Network'\n",
    "    print(\"Appropriate method according to the input is Artificial Neural Network\")\n",
    "    print('R-squared percentage for this method is = %.3f%%'  %  (r2_ANNK*100))\n",
    "if considered_best_method[0]=='XGBRegressor':\n",
    "    sample=sample[: ,feat_cols ]\n",
    "    sample=pd.DataFrame(sample)\n",
    "    sample.columns=x_sfs.columns\n",
    "    model=xg_reg\n",
    "    method='XGboost'\n",
    "    print(\"Appropriate method according to the input is XGboost\")\n",
    "    print('R-squared percentage for this method is = %.3f%%'  %  (r2_XK*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3  Predicting the battery energy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sample=model.predict(sample)\n",
    "y_pred_sample=np.around(y_pred_sample, decimals=3)\n",
    "\n",
    "print('Optimised value for the Battery Energy according to %s method is = %.3f (MWh)'  %  (method ,y_pred_sample [0]))\n",
    "# Optimised value for battery energy is = 0.331 (MWh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Discussion\n",
    "\n",
    "The purpose of this investigation was to predict the energy amount of Battery storage in order to optimize the operation of a smart grid. The data, which was used in this study, was collected from several websites. To achieve this goal six regression methods including Linear Regression, Ridge Regression, Lasso Regression and Elastic Net Regression XGboost and Artificial Neural Network were used.\n",
    "\n",
    "First, we started pre-processing the data and removed amounts that were out of normal range and also incomplete rows of data and duplicates. In this stage, in addition to managing missing values, we standardized features. Then using heat-map plot and feature selection methods, suitable features got extracted and we considered appropriate coefficients for them. After separating the data into training and test parts, several regression methods including the Linear Regression, the Ridge Regression, the Lasso Regression, the Elastic-Net Regression, the Artificial Neural Network and the XGboost became trained and tested.\n",
    "\n",
    "In The next step, we visualized amounts of errors (that is the difference between real values and the predicted values) in each method according to the predicted values. By looking at the plot we found out in ANN method the most of amounts of errors were close to zero. By looking at the next plot it is clear to see amounts of errors according to the methods and the amount of features. In the next stage, we can easily understand that among all regression methods, the Ridge regression model had the most and XGboost had the least accuracy.\n",
    "\n",
    "Then in correlation plot, it is obvious that ANN and XGboost has the highest correlation amount for the Pearsonr, the Spearmanr and the Kendalltau unlike the Elastic-Net method that had the lowest amounts. Next, in histogram plot of errors we saw the distribution of errors and what we can understand from this plot and the Error Box Plot in the following, is that again it is clear that in ANN method the most of the amounts of the errors are much closer to zero than other methods. After that in Error amounts plot by looking at the amounts of the mean square error(MSE), R2 score, Root Mean Square Error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) we can see that the operation of ANN and XGboost were better than others.\n",
    "\n",
    "In the last section an option has been considered for users to input the needed amounts and get the predicted value o the Battery Storage. In this section SVM classification method is optimized with the help of the GridSearchCV to find the best regressor according to the input. And finally you saw the predicted value for The Battery Storage and the regression method that was used and its R-squared percentage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
